{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using map-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import UnstructuredXMLLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "import pandas as pd\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import UnstructuredXMLLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import Tool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.memory.chat_message_histories import StreamlitChatMessageHistory\n",
    "from langchain.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\n",
    "    \"./data/train.csv\",\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "  char_text_splitter =  RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=0)\n",
    "  docs_split = char_text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = \"\"\"\n",
    "suggest some trials for breast cancer\n",
    "\"{text}\"\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
    "\n",
    "combine_prompt = \"\"\"\n",
    "suggest some trials for breast cancer\n",
    "\"{text}\"\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. A Randomized Phase III Trial of Adjuvant Chemotherapy with or without Atezolizumab in Patients with Triple Negative Breast Cancer\\n2. A Randomized Phase III Trial of Neoadjuvant Chemotherapy with or without Atezolizumab in Patients with Early Stage Breast Cancer\\n3. A Phase III Trial Comparing Neoadjuvant Chemotherapy Regimens in Women with Large Operable Breast Cancer\\n4. A Phase III Trial of Adjuvant Chemotherapy with or without Anthracycline-Based Regimens in Women with Early Breast Cancer\\n5. A Randomized Phase III Trial Comparing Hormonal Therapy to Chemotherapy in Women with Estrogen Receptor Positive, Node Positive Breast Cancer\\n6. A Randomized Phase III Trial Comparing Adjuvant Hormonal Therapy to Chemotherapy in Postmenopausal Women with Estrogen Receptor Positive, Node Positive Breast Cancer\\n7. A Clinical Trial to Test the Effectiveness of Combining Atezolizumab with Radiation Therapy and Chemotherapy in Treating Breast Cancer\\n8. A Clinical Trial to Compare the Efficacy of Immunotherapy with Monoclonal Antibodies Versus Chemotherapy in Treating Breast Cancer\\n9. A Clinical Trial'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_summarize_chain(llm=llm, chain_type=\"map_reduce\", map_prompt=map_prompt_template,combine_prompt=combine_prompt_template)\n",
    "model.run(docs_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking + summarizing individual chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_up_file_to_chunks(filename, chunk_size=2000, overlap=100):\n",
    "    encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()    \n",
    "        tokens = encoding.encode(text)\n",
    "    num_tokens = len(tokens)\n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(0, num_tokens, chunk_size - overlap):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/clinical_trials_modified.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: 2000 tokens\n",
      "Chunk 1: 2000 tokens\n",
      "Chunk 2: 2000 tokens\n",
      "Chunk 3: 2000 tokens\n",
      "Chunk 4: 2000 tokens\n",
      "Chunk 5: 2000 tokens\n",
      "Chunk 6: 2000 tokens\n",
      "Chunk 7: 2000 tokens\n",
      "Chunk 8: 2000 tokens\n",
      "Chunk 9: 2000 tokens\n",
      "Chunk 10: 2000 tokens\n",
      "Chunk 11: 2000 tokens\n",
      "Chunk 12: 2000 tokens\n",
      "Chunk 13: 2000 tokens\n",
      "Chunk 14: 2000 tokens\n",
      "Chunk 15: 2000 tokens\n",
      "Chunk 16: 2000 tokens\n",
      "Chunk 17: 2000 tokens\n",
      "Chunk 18: 2000 tokens\n",
      "Chunk 19: 2000 tokens\n",
      "Chunk 20: 2000 tokens\n",
      "Chunk 21: 2000 tokens\n",
      "Chunk 22: 2000 tokens\n",
      "Chunk 23: 2000 tokens\n",
      "Chunk 24: 2000 tokens\n",
      "Chunk 25: 2000 tokens\n",
      "Chunk 26: 2000 tokens\n",
      "Chunk 27: 2000 tokens\n",
      "Chunk 28: 2000 tokens\n",
      "Chunk 29: 2000 tokens\n",
      "Chunk 30: 2000 tokens\n",
      "Chunk 31: 2000 tokens\n",
      "Chunk 32: 2000 tokens\n",
      "Chunk 33: 2000 tokens\n",
      "Chunk 34: 2000 tokens\n",
      "Chunk 35: 2000 tokens\n",
      "Chunk 36: 2000 tokens\n",
      "Chunk 37: 2000 tokens\n",
      "Chunk 38: 2000 tokens\n",
      "Chunk 39: 2000 tokens\n",
      "Chunk 40: 2000 tokens\n",
      "Chunk 41: 2000 tokens\n",
      "Chunk 42: 2000 tokens\n",
      "Chunk 43: 2000 tokens\n",
      "Chunk 44: 2000 tokens\n",
      "Chunk 45: 2000 tokens\n",
      "Chunk 46: 2000 tokens\n",
      "Chunk 47: 2000 tokens\n",
      "Chunk 48: 2000 tokens\n",
      "Chunk 49: 2000 tokens\n",
      "Chunk 50: 2000 tokens\n",
      "Chunk 51: 2000 tokens\n",
      "Chunk 52: 2000 tokens\n",
      "Chunk 53: 2000 tokens\n",
      "Chunk 54: 2000 tokens\n",
      "Chunk 55: 2000 tokens\n",
      "Chunk 56: 2000 tokens\n",
      "Chunk 57: 2000 tokens\n",
      "Chunk 58: 2000 tokens\n",
      "Chunk 59: 2000 tokens\n",
      "Chunk 60: 2000 tokens\n",
      "Chunk 61: 2000 tokens\n",
      "Chunk 62: 2000 tokens\n",
      "Chunk 63: 2000 tokens\n",
      "Chunk 64: 2000 tokens\n",
      "Chunk 65: 2000 tokens\n",
      "Chunk 66: 2000 tokens\n",
      "Chunk 67: 2000 tokens\n",
      "Chunk 68: 2000 tokens\n",
      "Chunk 69: 2000 tokens\n",
      "Chunk 70: 2000 tokens\n",
      "Chunk 71: 2000 tokens\n",
      "Chunk 72: 2000 tokens\n",
      "Chunk 73: 2000 tokens\n",
      "Chunk 74: 2000 tokens\n",
      "Chunk 75: 2000 tokens\n",
      "Chunk 76: 2000 tokens\n",
      "Chunk 77: 2000 tokens\n",
      "Chunk 78: 2000 tokens\n",
      "Chunk 79: 2000 tokens\n",
      "Chunk 80: 2000 tokens\n",
      "Chunk 81: 2000 tokens\n",
      "Chunk 82: 2000 tokens\n",
      "Chunk 83: 2000 tokens\n",
      "Chunk 84: 2000 tokens\n",
      "Chunk 85: 2000 tokens\n",
      "Chunk 86: 2000 tokens\n",
      "Chunk 87: 2000 tokens\n",
      "Chunk 88: 2000 tokens\n",
      "Chunk 89: 2000 tokens\n",
      "Chunk 90: 2000 tokens\n",
      "Chunk 91: 271 tokens\n"
     ]
    }
   ],
   "source": [
    "chunks = break_up_file_to_chunks(filename)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i}: {len(chunk)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_engine(query):\n",
    "        prompt_response = []\n",
    "        encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "        chunks = break_up_file_to_chunks(filename)\n",
    "        for i, chunk in enumerate(chunks):    \n",
    "                prompt_request = query + encoding.decode(chunks[i])\n",
    "                messages = [{\"role\": \"system\", \"content\": \"You help query the clinical trial data provided and answer any questions about the same\"}]    \n",
    "                messages.append({\"role\": \"user\", \"content\": prompt_request})    \n",
    "                response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                        messages=messages,\n",
    "                        temperature=0,\n",
    "                        max_tokens=500,\n",
    "                        top_p=1,\n",
    "                        frequency_penalty=0,\n",
    "                        presence_penalty=0\n",
    "                )\n",
    "                \n",
    "                prompt_response.append(response[\"choices\"][0][\"message\"]['content'].strip())\n",
    "        \n",
    "        prompt_request = \"Consolidate the answer and give a cohesive response: \" + str(prompt_response)\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You help query the clinical trial data provided and answer any questions about the same\"}]    \n",
    "        messages.append({\"role\": \"user\", \"content\": prompt_request})   \n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine(\"suggest 5 trials related to the nose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are 5 clinical trials related to the nose:\\n\\n1. Trial: NRG-HN001\\n   - Title: Randomized Phase II and Phase III Studies of Individualized Treatment for Nasopharyngeal Carcinoma Based on Biomarker Epstein Barr Virus (EBV) Deoxyribonucleic Acid (DNA)\\n   - NCT ID: NCT02135042\\n   - Investigator Name: Rupali Nabar\\n   - Status: Open to Accrual\\n   - Eligibility: 18 Years and older (Adult, Older Adult)\\n   - Description: This trial aims to study individualized treatment for nasopharyngeal carcinoma based on the biomarker EBV DNA.\\n   - Phase: Phase II/III\\n   - Treatment Type: Not specified\\n   - Age Description: 18 Years and older (Adult, Older Adult)\\n   - Scope Description: Not specified\\n   - Location Name: Not specified\\n   - Summary: This trial investigates the use of individualized treatment for nasopharyngeal carcinoma based on the biomarker EBV DNA. Patients will undergo standard concurrent chemotherapy and radiation therapy, followed by additional treatment based on their EBV DNA levels.\\n\\n2. Trial Name: \"Randomized Phase II/III Trial for Locoregionally Advanced Non-Metastatic Nasopharyngeal Cancer\"\\n   - Description: This trial investigates the effectiveness of different chemotherapy regimens after standard concurrent chemotherapy and radiation therapy for nasopharyngeal cancer.\\n   - Trial ID: N/A\\n   - Phase: II/III\\n   - Intervention: Treatment\\n   - Population: Adults\\n   - Sponsor: CFCCC, Radiation Therapy Oncology Group, NRG Oncology\\n   - Cancer Type: Nasopharyngeal Cancer\\n\\n3. Trial Name: \"Phase II Study of Vemurafenib and Cobimetinib in BRAF V600E Mutation Positive Craniopharyngioma\"\\n   - Trial Identifier: NCT04181150\\n   - Description: This trial aims to evaluate the effectiveness of vemurafenib and cobimetinib in treating patients with BRAF V600E mutation positive craniopharyngioma. The central pathology review will include immunohistochemistry (IHC) testing for BRAF V600E mutation (VE1 clone) and beta-catenin IHC (membranous, non-nuclear pattern) if needed to confirm the diagnosis of papillary craniopharyngioma.\\n\\n4. Trial Name: \"Phase II Study of Pembrolizumab in Patients with Recurrent or Metastatic Sinonasal Squamous Cell Carcinoma\"\\n   - Trial Identifier: NCT03631347\\n   - Description: This trial investigates the effectiveness of pembrolizumab in treating patients with recurrent or metastatic sinonasal squamous cell carcinoma. The central pathology review will involve the evaluation of tumor pathology specimens and may include immunohistochemistry testing.\\n\\n5. Trial Name: \"Phase III Trial of Concurrent Chemoradiation with or without Atezolizumab for Localized MIBC\"\\n   - Trial ID: NCT03775265\\n   - Investigator: Ramy Yaacoub\\n   - Status: Open to accrual\\n   - Age Group: Adult\\n   - Description: This trial aims to evaluate the effectiveness of chemotherapy and radiation therapy with or without atezolizumab in treating patients with localized muscle invasive bladder cancer.\\n\\nPlease note that the information provided is based on the given data and may not be complete. It is recommended to refer to the official clinical trial website for more accurate and up-to-date information.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"]['content'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data (mainly just some pandas work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import UnstructuredXMLLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/clinical_trials.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_combine = [f'DISEASE_SITES/DISEASE_SITE/{i}' for i in range(42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['disease_sites'] = df[columns_to_combine].apply(lambda row: ', '.join(row.dropna()), axis=1)\n",
    "df.drop(columns=columns_to_combine, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_combine = [f'SPONSOR_NAMES/SPONSOR_NAME/{i}' for i in range(4)]\n",
    "df['sponsor_names'] = df[columns_to_combine].apply(lambda row: ', '.join(row.dropna()), axis=1)\n",
    "df.drop(columns=columns_to_combine, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_combine = [f'THERAPY_NAMES/THERAPY_NAME/{i}' for i in range(3)]\n",
    "df['therapy_names'] = df[columns_to_combine].apply(lambda row: ', '.join(row.dropna()), axis=1)\n",
    "df.drop(columns=columns_to_combine, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_combine = [f'DRUG_NAMES/DRUG_NAME/{i}' for i in range(5)]\n",
    "df['drug_names'] = df[columns_to_combine].apply(lambda row: ', '.join(row.dropna()), axis=1)\n",
    "df.drop(columns=columns_to_combine, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/clinical_trials_modified.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml('./data/clinical_trials_original.xml',xpath=\"/TRIAL/PROTOCOL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/clinical_trials_original.xml', 'r') as file_in, open('./data/test.txt', 'w') as file_out:\n",
    "    data = file_in.read()\n",
    "    file_out.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not os.path.isfile('./data/clinical_trials_original.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FAISS/chroma (with modified/prep-processed CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "import pandas as pd\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import UnstructuredXMLLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('./data/clinical_trials_original.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "protocol_data = []\n",
    "\n",
    "# Iterate through each <PROTOCOL> element\n",
    "for protocol in root.findall('.//PROTOCOL'):\n",
    "    protocol_dict = {}\n",
    "    # Extract data from XML tags and add it to the dictionary\n",
    "    #protocol_dict['PROTOCOL_NO'] = protocol.find('PROTOCOL_NO').text\n",
    "    protocol_dict['TITLE'] = protocol.find('TITLE').text\n",
    "    #protocol_dict['NCT_ID'] = protocol.find('NCT_ID').text\n",
    "    protocol_dict['SHORT_TITLE'] = protocol.find('SHORT_TITLE').text\n",
    "    protocol_dict['INVESTIGATOR_NAME'] = protocol.find('INVESTIGATOR_NAME').text\n",
    "    protocol_dict['STATUS'] = protocol.find('STATUS').text\n",
    "    protocol_dict['ELIGIBILITY'] = protocol.find('ELIGIBILITY').text\n",
    "    protocol_dict['DETAILED_ELIGIBILITY'] = protocol.find('DETAILED_ELIGIBILITY').text if protocol.find('DETAILED_ELIGIBILITY') is not None else ''\n",
    "    protocol_dict['DESCRIPTION'] = protocol.find('DESCRIPTION').text\n",
    "    protocol_dict['PHASE_DESC'] = protocol.find('PHASE_DESC').text\n",
    "    protocol_dict['TREATMENT_TYPE_DESC'] = protocol.find('TREATMENT_TYPE_DESC').text\n",
    "    protocol_dict['AGE_DESCRIPTION'] = protocol.find('AGE_DESCRIPTION').text\n",
    "    protocol_dict['SCOPE_DESC'] = protocol.find('SCOPE_DESC').text\n",
    "    protocol_dict['MODIFIED_DATE'] = protocol.find('MODIFIED_DATE').text\n",
    "    protocol_dict['DEPARTMENT_NAME'] = protocol.find('DEPARTMENT_NAME').text\n",
    "    # Extract SPONSOR_NAMES\n",
    "    sponsor_names = [sponsor.text for sponsor in protocol.findall('.//SPONSOR_NAME')]\n",
    "    protocol_dict['SPONSOR_NAMES'] = ', '.join(sponsor_names)\n",
    "    # Extract DISEASE_SITES\n",
    "    disease_sites = [site.text for site in protocol.findall('.//DISEASE_SITE')]\n",
    "    protocol_dict['DISEASE_SITES'] = ', '.join(disease_sites)\n",
    "    # Extract DRUG_NAMES (if available)\n",
    "    drugs = protocol.findall('.//DRUG_NAMES')\n",
    "    if drugs:\n",
    "        protocol_dict['DRUG_NAMES'] = ', '.join([drug.text if drug.text is not None else '' for drug in drugs])\n",
    "    else:\n",
    "        protocol_dict['DRUG_NAMES'] = ''\n",
    "\n",
    "    # Extract THERAPY_NAMES (if available)\n",
    "    therapies = protocol.findall('.//THERAPY_NAMES')\n",
    "    if therapies:\n",
    "        protocol_dict['THERAPY_NAMES'] = ', '.join([therapy.text if therapy.text is not None else '' for therapy in therapies])\n",
    "    else:\n",
    "        protocol_dict['THERAPY_NAMES']= ''\n",
    "\n",
    "    \n",
    "\n",
    "    # Append the protocol data to the list\n",
    "    protocol_data.append(protocol_dict)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(protocol_data)\n",
    "df.to_csv('./data/clinical_trials_from_xml.csv',  index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader('./data/train.csv')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='TITLE: Genetic Testing in Guiding Treatment for Patients with Brain Metastases\\nSHORT_TITLE: Genetic Testing in Guiding Treatment for Patients with Brain Metastases\\nINVESTIGATOR_NAME: Yoon Jae Choi\\nSTATUS: OPEN TO ACCRUAL\\nELIGIBILITY: Adults\\nDETAILED_ELIGIBILITY: Pre-registration Eligibility:\\n\\n- Tissue available for biomarker testing (any brain metastasis tissue and extracranial site from any prior resection or biopsy)\\n\\nRegistration Eligibility:\\n\\n- Participants must have histologically confirmed parenchymal metastatic disease to the brain from any solid tumor\\n- Female participants must not be pregnant or breastfeeding\\n- Ability to obtain MRIs with contrast\\nDESCRIPTION: This phase II trial studies how well genetic testing works in guiding treatment for patients with solid tumors that have spread to the brain. Several genes have been found to be altered or mutated in brain metastases such as NTRK, ROS1, CDK or PI3K. Medications that target these genes such as abemaciclib, paxalisib, and entrectinib may stop the growth of tumor cells by blocking some of the enzymes needed for cell growth. Genetic testing may help doctors tailor treatment for each mutation.\\nPHASE_DESC: II\\nTREATMENT_TYPE_DESC: Treatment\\nAGE_DESCRIPTION: Adults\\nSCOPE_DESC: National\\nMODIFIED_DATE: 2021-04-21T09:36:35\\nDEPARTMENT_NAME: CFCCC\\nSPONSOR_NAMES: Alliance, Alliance for Clinical Trials in Oncology\\nDISEASE_SITES: Melanoma, Skin, Brain and Nervous System, Breast, Lung\\nDRUG_NAMES: \\nTHERAPY_NAMES: ', metadata={'source': './data/train.csv', 'row': 21})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using FAISS \n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "#retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Create vector store + save using chroma\n",
    "vectordb = Chroma.from_documents(documents = docs, embedding = embeddings, persist_directory=\"./embeddings\")\n",
    "vectordb.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory = \"./embeddings\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    " \n",
    "chain = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(temperature=0.0, model_name='gpt-3.5-turbo', streaming=True, callbacks=[StreamingStdOutCallbackHandler()]),retriever=vectordb.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.5}), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any ongoing clinical trials for brain cancer?Yes, there are ongoing clinical trials for brain cancer. Here are a few examples:\n",
      "\n",
      "1. Title: Genetic Testing in Guiding Treatment for Patients with Brain Metastases\n",
      "   Investigator: Yoon Jae Choi\n",
      "   Status: Open to accrual\n",
      "   Description: This phase II trial is studying how well genetic testing works in guiding treatment for patients with solid tumors that have spread to the brain. The goal is to tailor treatment based on genetic mutations.\n",
      "   Disease Sites: Melanoma, Skin, Brain and Nervous System, Breast, Lung\n",
      "\n",
      "2. Title: Phase II Trial of the Immune Checkpoint Inhibitor Nivolumab in Patients with Recurrent Select Rare CNS Cancers\n",
      "   Investigator: Daniela Bota\n",
      "   Status: Open to accrual\n",
      "   Description: This phase II trial is testing the effectiveness of the immunotherapy drug nivolumab in treating patients with rare central nervous system (CNS) tumors.\n",
      "   Disease Sites: Brain and Nervous System\n",
      "\n",
      "3. Title: Phase II Trial of BRAF/MEK Inhibitors in Papillary Craniopharyngiomas\n",
      "   Investigator: Yoon Jae Choi\n",
      "   Status: Open to accrual\n",
      "   Description: This phase II trial is studying the use of vemurafenib and cobimetinib in treating patients with BRAF V600E mutation positive craniopharyngioma.\n",
      "   Disease Sites: Brain and Nervous System\n",
      "\n",
      "4. Title: Phase II, Single Arm Study Of NOVOTTF-200A In Bevacizumab-Naive Subjects With Recurrent WHO Grade III Malignant Astrocytoma\n",
      "   Investigator: Daniela Bota\n",
      "   Status: Open to accrual\n",
      "   Description: This phase II study is evaluating the use of NOVOTTF-200A (Optune) in treating patients with recurrent WHO Grade III malignant astrocytoma.\n",
      "   Disease Sites: Brain and Nervous System\n",
      "\n",
      "Please note that these are just a few examples, and there may be other ongoing clinical trials for brain cancer as well."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'Yes, there are ongoing clinical trials for brain cancer. Here are a few examples:\\n\\n1. Title: Genetic Testing in Guiding Treatment for Patients with Brain Metastases\\n   Investigator: Yoon Jae Choi\\n   Status: Open to accrual\\n   Description: This phase II trial is studying how well genetic testing works in guiding treatment for patients with solid tumors that have spread to the brain. The goal is to tailor treatment based on genetic mutations.\\n   Disease Sites: Melanoma, Skin, Brain and Nervous System, Breast, Lung\\n\\n2. Title: Phase II Trial of the Immune Checkpoint Inhibitor Nivolumab in Patients with Recurrent Select Rare CNS Cancers\\n   Investigator: Daniela Bota\\n   Status: Open to accrual\\n   Description: This phase II trial is testing the effectiveness of the immunotherapy drug nivolumab in treating patients with rare central nervous system (CNS) tumors.\\n   Disease Sites: Brain and Nervous System\\n\\n3. Title: Phase II Trial of BRAF/MEK Inhibitors in Papillary Craniopharyngiomas\\n   Investigator: Yoon Jae Choi\\n   Status: Open to accrual\\n   Description: This phase II trial is studying the use of vemurafenib and cobimetinib in treating patients with BRAF V600E mutation positive craniopharyngioma.\\n   Disease Sites: Brain and Nervous System\\n\\n4. Title: Phase II, Single Arm Study Of NOVOTTF-200A In Bevacizumab-Naive Subjects With Recurrent WHO Grade III Malignant Astrocytoma\\n   Investigator: Daniela Bota\\n   Status: Open to accrual\\n   Description: This phase II study is evaluating the use of NOVOTTF-200A (Optune) in treating patients with recurrent WHO Grade III malignant astrocytoma.\\n   Disease Sites: Brain and Nervous System\\n\\nPlease note that these are just a few examples, and there may be other ongoing clinical trials for brain cancer as well.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain( {\"question\":\"trials for brain cancer\"},  return_only_outputs=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the first clinical trial mentioned in the list above?The name of the first clinical trial mentioned in the list above is \"PLS Natural History Study (PNHS)\"."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The name of the first clinical trial mentioned in the list above is \"PLS Natural History Study (PNHS)\".'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run( \"name of the first clinical trial in the list reabove?\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using compression retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vectordb_persist.as_retriever())\n",
    "\n",
    "# compressed_docs = compression_retriever.get_relevant_documents(\"What did the president say about Ketanji Jackson Brown\")\n",
    "# pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_new =  RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature=0.0, model_name='gpt-3.5-turbo'),retriever=compression_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, here are a couple of clinical trials that may be relevant for brain cancer:\\n\\n1. Trial Name: \"Study of Abemaciclib in Patients With Brain Metastases\"\\n   - Description: This trial is investigating the effectiveness of abemaciclib, a medication that targets CDK enzymes, in patients with brain metastases from any solid tumor.\\n   - Eligibility Criteria: Participants must have histologically confirmed parenchymal metastatic disease to the brain from any solid tumor.\\n   - Sponsor: Multiple sponsors, including academic institutions and pharmaceutical companies.\\n\\n2. Trial Name: \"Vemurafenib and Cobimetinib in Treating Patients With BRAF V600E Mutation-Positive Craniopharyngioma\"\\n   - Description: This trial is evaluating the efficacy of vemurafenib and cobimetinib, which block enzymes needed for cell growth, in patients with papillary craniopharyngioma that has the BRAF V600E mutation.\\n   - Eligibility Criteria: Participants must have histologically proven papillary craniopharyngioma with positive BRAF V600E mutation.\\n   - Sponsor: Alliance, a collaborative group of researchers and institutions.\\n\\nPlease note that these are just examples, and there may be other ongoing clinical trials for brain cancer. It is important to consult with a healthcare professional or search clinical trial databases for the most up-to-date information on available trials.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run({\"query\": \"suggest some trials for brain cancer\",\"chat_history\":[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pandas multi-dataframe agent with chunking(with modified/pre-processed CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/clinical_trials_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 20  # adjust this value to suit your needs\n",
    "chunks = [df[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "agent = create_pandas_dataframe_agent( ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo'), chunks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.run(\"suggest some trials for brain cancer\") -- THROWS RATE LIMIT ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using vectorstore + agents (via tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.txt', 'w') as file:\n",
    "    for index, row in df.iterrows():\n",
    "        file.write(f\"Trial {index+1}\\n\")\n",
    "        for col_name, value in row.items():\n",
    "            file.write(f\"{col_name} - {value}\\n\")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader('./data/train.csv')\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store + save using chroma\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents = docs, embedding = embeddings, persist_directory=\"./embeddings\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "general_system_template = \"\"\" \n",
    "Given a specific context, please give the most relevant answer to the question using the context given, covering the required advices in general. If there is no direct answer, try to give the closest match before saying you don't know the answer. If the request is for a clinical trial then look for the keyword and any relevant keywords in 'Disease sites' before saying nothing exists. For ex: If the user asks about trials related to the Nose, but it doesn't exist, look for trials in the closest surrounding areas like nose/throat and suggest the same. Only answer based on the context, nothing outside of it.\n",
    " ----\n",
    "{context}\n",
    "----\n",
    "\"\"\"\n",
    "general_user_template = \"Question:```{question}```\"\n",
    "messages = [\n",
    "            SystemMessagePromptTemplate.from_template(general_system_template),\n",
    "            HumanMessagePromptTemplate.from_template(general_user_template)\n",
    "]\n",
    "qa_prompt = ChatPromptTemplate.from_messages( messages )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# # vectordb_text = Chroma(persist_directory = \"./text_embeddings\", embedding_function=embeddings)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model_name='gpt-3.5-turbo', streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "chain =ConversationalRetrievalChain.from_llm(llm=llm,retriever=vectordb.as_retriever(), memory=memory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two clinical trials related to nose conditions:\n",
      "\n",
      "1. TITLE: A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults.\n",
      "   SHORT_TITLE: Enlighten 2\n",
      "   DESCRIPTION: This trial aims to evaluate the efficacy and safety of LYR-210 compared to a sham control for the treatment of chronic rhinosinusitis (CRS) in adults. It is a 24-week study with a 24-week treatment period.\n",
      "   PHASE_DESC: III\n",
      "   TREATMENT_TYPE_DESC: Drug\n",
      "   DISEASE_SITES: Ear/ Nose/ Throat (ENT) - Otolaryngologic\n",
      "   SPONSOR_NAMES: Medpace, Inc., Lyra Therapeutics, Inc.\n",
      "\n",
      "2. TITLE: Phase II Trial of BRAF/MEK Inhibitors in Papillary Craniopharyngiomas\n",
      "   SHORT_TITLE: Ph II Trial of BRAF/MEK Inhibitors in Papillary Craniopharyngiomas\n",
      "   DESCRIPTION: This phase II trial investigates the effectiveness of vemurafenib and cobimetinib, which are BRAF/MEK inhibitors, in treating patients with papillary craniopharyngiomas. The study aims to determine if these inhibitors can stop the growth of tumor cells by blocking certain enzymes needed for cell growth.\n",
      "   PHASE_DESC: II\n",
      "   TREATMENT_TYPE_DESC: Treatment\n",
      "   DISEASE_SITES: Brain and Nervous System\n",
      "   SPONSOR_NAMES: Alliance\n",
      "\n",
      "Please note that these trials may have specific eligibility criteria and may not be suitable for everyone. It is important to consult with a healthcare professional or contact the trial sponsor for more information about participation."
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "res = chain({\"question\":\"some trials for the nose\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(\"some trials for the nose\", res[\"answer\"])]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the eligibility criteria for trial 1 from the list provided above?The eligibility criteria for trial 1 are as follows:\n",
      "\n",
      "Inclusion Requirements:\n",
      "- Must be 18 years of age or older\n",
      "\n",
      "Exclusion Requirements:\n",
      "- Pregnant or breastfeeding\n",
      "\n",
      "Please note that this may not be a complete list of eligibility criteria. It is recommended to consult with the study team for a thorough assessment of eligibility."
     ]
    }
   ],
   "source": [
    "res2 = chain({\"question\":\"eligibility criteria for trial 1 from above list\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "tools = []\n",
    "tools.append(\n",
    "                    Tool(\n",
    "                         \n",
    "                        name=\"search_clinical_trials_database\"  ,\n",
    "                        description=\"useful when you want to answer questions about the clinical trial database\",\n",
    "                        func=RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature=0.0, model_name='gpt-3.5-turbo', streaming=True, callbacks=[StreamingStdOutCallbackHandler()]),retriever=vectordb.as_retriever()),\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# agent_kwargs = {\n",
    "#     \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "# }\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. Display results in a bulleted list where possible. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(\n",
    "#     temperature=0,\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     # model_kwargs={\"prompt\":prompt}\n",
    "# )\n",
    "# llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "\n",
    "# agent = initialize_agent(tools, llm_chain, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, memory=memory,handle_parsing_errors=\"Check your output and make sure it conforms!\")\n",
    "from langchain import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any information related to the nose in the provided context.I'm sorry, but I don't have any information about a study specifically related to nasal conditions.The first study mentioned, titled \"A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults,\" is specifically focused on the treatment of chronic rhinosinusitis (CRS) in adults. It is a randomized, controlled trial evaluating the efficacy and safety of LYR-210 compared to a sham control.\n",
      "\n",
      "The second study mentioned, titled \"A Randomized, Double-blind, Placebo-controlled, Phase 3 Study of the Efficacy and Safety of Inhaled Treprostinil in Subjects with Idiopathic Pulmonary Fibrosis,\" is not related to sinus conditions. It is a study evaluating the efficacy and safety of inhaled treprostinil in subjects with idiopathic pulmonary fibrosis.\n",
      "\n",
      "The third study mentioned, titled \"Gronigen International Study on Sentinel Nodes in Vulvar Cancer (GROINSS-V) III: A Prospective Phase II Treatment Trial,\" is focused on vulvar cancer and does not pertain to sinus conditions.\n",
      "\n",
      "The fourth study mentioned, titled \"A Prospective, Multicenter, Open-Label Single Arm Study Evaluating the Safety and Efficacy of Selective Internal Radiation Therapy (SIRT) Using SIR-Spheres Y-90 Resin Microspheres on Duration of Response (DoR) and Objective Response Rate (ORR) in Unresectable Hepatocellular Carcinoma (HCC) Patients (DOORwaY90 Study),\" is also unrelated to sinus conditions. It is a study evaluating the safety and efficacy of selective internal radiation therapy using SIR-Spheres Y-90 resin microspheres for the treatment of unresectable hepatocellular carcinoma (HCC).\n",
      "\n",
      "Therefore, none of the mentioned studies are specifically focused on sinus conditions or sinusitis."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first study mentioned, titled \"A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults,\" is specifically focused on the treatment of chronic rhinosinusitis (CRS) in adults. It is a randomized, controlled trial evaluating the efficacy and safety of LYR-210 compared to a sham control.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent(\"trials for blood cancer\")['output']\n",
    "agent_chain.run(input=\"trials for nose\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, there is no specific clinical trial mentioned for nose-related conditions. However, since the context mentions chronic rhinosinusitis (CRS), which is a condition affecting the nose and sinuses, it is recommended to consider participating in the clinical trial titled \"A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults\" (Enlighten 2). This trial is specifically for adults diagnosed with CRS and aims to evaluate the efficacy and safety of LYR-210 for the treatment of CRS. It is always advisable to consult with a healthcare professional for personalized advice and to determine if participating in a clinical trial is suitable for your specific condition."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the given context, it is recommended to consider participating in the clinical trial titled \"A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults\" (Enlighten 2). This trial is specifically for adults diagnosed with CRS and aims to evaluate the efficacy and safety of LYR-210 for the treatment of CRS. It is always advisable to consult with a healthcare professional for personalized advice and to determine if participating in a clinical trial is suitable for your specific condition.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"okay give me those trials then\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlighten 2 is a phase III clinical trial for the treatment of Chronic Rhinosinusitis (CRS) in adults. The trial is evaluating the efficacy and safety of LYR-210 compared to a sham control. To be eligible for the trial, participants must be 18 years or older, diagnosed with CRS, have undergone at least 2 trials of medical treatments in the past, have a mean 3 cardinal symptom (3CS) score, and have bilateral ethmoid disease confirmed on CT. It is important to note that this trial is currently open to accrual."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To be eligible for the trial, participants must be 18 years or older, diagnosed with CRS, have undergone at least 2 trials of medical treatments in the past, have a mean 3 cardinal symptom (3CS) score, and have bilateral ethmoid disease confirmed on CT. It is important to note that this trial is currently open to accrual.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"eligibility for trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Phase III trial is evaluating the efficacy and safety of LYR-210 for the treatment of Chronic Rhinosinusitis (CRS) in adults. The trial is randomized, blinded, controlled, and conducted in parallel groups. The eligibility criteria include being 18 years or older, diagnosed with CRS, having undergone at least 2 trials of medical treatments in the past, and having a mean 3 cardinal symptom (3CS) score. Bilateral ethmoid disease confirmed on CT is also required. It is important to note that the trial is currently open to accrual."
     ]
    }
   ],
   "source": [
    "res = agent_chain.run(input=\"what about exclusion criteria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using conversational retrieval agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(docs, embeddings)\n",
    "vectordb.save_local(\"faiss_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.load_local(\"faiss_embeddings\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reach out about Oncore + Qualy\n",
    "# Get scripts from Daniella\n",
    "# Prompt people to ask the right questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "tool = create_retriever_tool(\n",
    "    docsearch.as_retriever(), \n",
    "    \"search_clinical_trials_database\",\n",
    "    \"Searches and returns documents regarding clinical trials\"\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "llm = ChatOpenAI(temperature = 0, \n",
    "                 model_name=\"gpt-3.5-turbo\",\n",
    "                 streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some clinical trials related to blood cancer:\n",
      "\n",
      "1. Title: A Study to Evaluate Long-Term Safety of CAR-T Cell Therapy in Patients with Hematologic Malignancies\n",
      "   - Investigator: Susan O'Brien\n",
      "   - Status: Open to accrual\n",
      "   - Description: This is a non-interventional, long-term safety study of allogeneic CAR-T cell therapy in patients with hematologic malignancies. The purpose is to collect long-term observational data to identify and understand potential late side effects in patients who have received CAR-T cell therapies.\n",
      "   - Disease Sites: Multiple Myeloma, Non-Hodgkin's Lymphoma, Hodgkin's Lymphoma, Lymphoid Leukemia, Myeloid and Monocytic Leukemia, Other Hematopoietic Leukemia\n",
      "   - Sponsor: Caribou Biosciences, Inc.\n",
      "\n",
      "2. Title: Blood Collection Protocol for the Analysis of Exosomes in Patients with Breast Cancer\n",
      "   - Investigator: Ritesh Parajuli\n",
      "   - Status: Open to accrual\n",
      "   - Description: The purpose of this research study is to determine a group of particles in the blood called exosomes that may be associated with response to treatment or could predict recurrence and side effects in patients with breast cancer.\n",
      "   - Disease Sites: Breast\n",
      "   - Sponsor: UCI, Hitachi Chemical Research Center\n",
      "\n",
      "3. Title: Prospective Study to Assess the Role of Plasma Exosomal Gene Signature and PD-L1 Expression to Predict Response to Treatment in Solid Organ Malignancies\n",
      "   - Investigator: Maheswari Senthil\n",
      "   - Status: Open to accrual\n",
      "   - Description: This is a phase 2 prospective study to evaluate a blood test from patients with solid organ malignancies to predict response to treatment.\n",
      "   - Disease Sites: Melanoma, Skin, Rectum, Lung, Stomach, Colon, Kidney, Liver\n",
      "   - Sponsor: UCI\n",
      "\n",
      "4. Title: OPtimal Treatment by Invoking Biologic Clusters in Renal Cell Carcinoma (OPTIC RCC)\n",
      "   - Investigator: Nataliya Mar\n",
      "   - Status: IRB initial approval\n",
      "   - Description: This phase II trial tests whether using genetic testing of tumor tissue to select the optimal treatment regimen works in treating patients with clear cell renal cell (kidney) cancer that has spread to other places in the body. The purpose is to learn if genetic testing of tumor tissue may help doctors select the optimal treatment regimen to which advanced kidney cancer is more likely to respond.\n",
      "   - Disease Sites: Kidney\n",
      "   - Sponsor: Vanderbilt University Medical Center\n",
      "\n",
      "Please note that the information provided is based on the available clinical trial database and may not be exhaustive. It is recommended to consult with healthcare professionals or visit clinical trial websites for more detailed and up-to-date information on specific trials."
     ]
    }
   ],
   "source": [
    "res = agent_executor ({\"input\": \"trials for blood cancer\"})['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some clinical trials related to the nose:\n",
      "\n",
      "1. Title: A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults.\n",
      "   - Investigator: Naveen Bhandarkar\n",
      "   - Status: Open to accrual\n",
      "   - Description: This is a 24-week, multicenter, phase III trial to evaluate the efficacy and safety of LYR-210 compared with sham control for the treatment of chronic rhinosinusitis in adults. The trial aims to assess the effectiveness of LYR-210 in improving symptoms and quality of life in patients with CRS.\n",
      "   - Disease Sites: Ear/ Nose/ Throat (ENT) - Otolaryngologic\n",
      "   - Sponsors: Medpace, Inc., Lyra Therapeutics, Inc.\n",
      "\n",
      "2. Title: Randomized Phase II and Phase III Studies of Individualized Treatment for Nasopharyngeal Carcinoma Based on Biomarker Epstein Barr Virus (EBV) Deoxyribonucleic Acid (DNA)\n",
      "   - Investigator: Rupali Nabar\n",
      "   - Status: Open to accrual\n",
      "   - Description: This is a phase II/III trial for patients with nasopharyngeal carcinoma. The trial aims to evaluate the effectiveness of individualized treatment based on the biomarker Epstein Barr Virus (EBV) DNA. Patients will undergo standard concurrent chemotherapy and radiation therapy, and based on the presence or absence of detectable EBV DNA, they will be randomized to different treatment regimens.\n",
      "   - Disease Sites: Lip, Oral Cavity and Pharynx\n",
      "   - Sponsors: Radiation Therapy Oncology Group, NRG Oncology\n",
      "\n",
      "Please note that the information provided is based on the available clinical trial database and may not be exhaustive. It is recommended to consult with healthcare professionals or visit clinical trial websites for more detailed and up-to-date information on specific trials."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are some clinical trials related to the nose:\\n\\n1. Title: A Phase III, Randomized, Blinded, Controlled, Parallel-Group Trial to Evaluate the Efficacy and Safety of LYR-210 for the Treatment of Chronic Rhinosinusitis (CRS) in Adults.\\n   - Investigator: Naveen Bhandarkar\\n   - Status: Open to accrual\\n   - Description: This is a 24-week, multicenter, phase III trial to evaluate the efficacy and safety of LYR-210 compared with sham control for the treatment of chronic rhinosinusitis in adults. The trial aims to assess the effectiveness of LYR-210 in improving symptoms and quality of life in patients with CRS.\\n   - Disease Sites: Ear/ Nose/ Throat (ENT) - Otolaryngologic\\n   - Sponsors: Medpace, Inc., Lyra Therapeutics, Inc.\\n\\n2. Title: Randomized Phase II and Phase III Studies of Individualized Treatment for Nasopharyngeal Carcinoma Based on Biomarker Epstein Barr Virus (EBV) Deoxyribonucleic Acid (DNA)\\n   - Investigator: Rupali Nabar\\n   - Status: Open to accrual\\n   - Description: This is a phase II/III trial for patients with nasopharyngeal carcinoma. The trial aims to evaluate the effectiveness of individualized treatment based on the biomarker Epstein Barr Virus (EBV) DNA. Patients will undergo standard concurrent chemotherapy and radiation therapy, and based on the presence or absence of detectable EBV DNA, they will be randomized to different treatment regimens.\\n   - Disease Sites: Lip, Oral Cavity and Pharynx\\n   - Sponsors: Radiation Therapy Oncology Group, NRG Oncology\\n\\nPlease note that the information provided is based on the available clinical trial database and may not be exhaustive. It is recommended to consult with healthcare professionals or visit clinical trial websites for more detailed and up-to-date information on specific trials.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor ({\"input\": \"trials for the nose\"})['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eligibility criteria for Trial 2, \"Randomized Phase II and Phase III Studies of Individualized Treatment for Nasopharyngeal Carcinoma Based on Biomarker Epstein Barr Virus (EBV) Deoxyribonucleic Acid (DNA)\", are as follows:\n",
      "\n",
      "Inclusion Criteria:\n",
      "- Biopsy-proven (from primary lesion and/or lymph nodes) diagnosis of cancer of the nasopharynx.\n",
      "- Patients must have detectable pretreatment plasma EBV DNA, determined by the central lab prior to Step 2 registration.\n",
      "- Stage II-IVB disease (AJCC, 7th ed.) with no evidence of distant metastasis.\n",
      "- History/physical examination by a Medical Oncologist or Clinical Oncologist or Radiation Oncologist or ENT, which must include an endoscopic evaluation, a complete list of current medications, and assessment of weight and weight loss in the past 6 months within 21 days prior to registration.\n",
      "- Evaluation of tumor extent required within 28 days prior to registration: MRI of the nasopharynx and neck; or CT of the nasopharynx and neck with  3 mm contiguous slices with contrast and bone windows (to evaluate base of skull involvement).\n",
      "\n",
      "Exclusion Criteria:\n",
      "- Prior invasive malignancy (except node-negative, non-melanomatous skin cancer) unless disease-free for a minimum of 1095 days (3 years).\n",
      "- Prior systemic chemotherapy for the study cancer.\n",
      "- Prior radiotherapy to the region of the study cancer that would result in overlap of radiation therapy fields.\n",
      "- Patients with hearing loss assessed to be primarily sensorine"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The eligibility criteria for Trial 2, \"Randomized Phase II and Phase III Studies of Individualized Treatment for Nasopharyngeal Carcinoma Based on Biomarker Epstein Barr Virus (EBV) Deoxyribonucleic Acid (DNA)\", are as follows:\\n\\nInclusion Criteria:\\n- Biopsy-proven (from primary lesion and/or lymph nodes) diagnosis of cancer of the nasopharynx.\\n- Patients must have detectable pretreatment plasma EBV DNA, determined by the central lab prior to Step 2 registration.\\n- Stage II-IVB disease (AJCC, 7th ed.) with no evidence of distant metastasis.\\n- History/physical examination by a Medical Oncologist or Clinical Oncologist or Radiation Oncologist or ENT, which must include an endoscopic evaluation, a complete list of current medications, and assessment of weight and weight loss in the past 6 months within 21 days prior to registration.\\n- Evaluation of tumor extent required within 28 days prior to registration: MRI of the nasopharynx and neck; or CT of the nasopharynx and neck with  3 mm contiguous slices with contrast and bone windows (to evaluate base of skull involvement).\\n\\nExclusion Criteria:\\n- Prior invasive malignancy (except node-negative, non-melanomatous skin cancer) unless disease-free for a minimum of 1095 days (3 years).\\n- Prior systemic chemotherapy for the study cancer.\\n- Prior radiotherapy to the region of the study cancer that would result in overlap of radiation therapy fields.\\n- Patients with hearing loss assessed to be primarily sensorine'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor({\"input\": \"eligibility criteria for trial 2\"})['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert CSV to PDFs/text files, embed and see results with both RetrievalQA and conversational agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of talk about how it is not very meaningful or efficient to generate embeddings directly from CSVs since gen AI models don't function very well with tabular dat and vector embeddings are better suited to more natural language datasets. Hence, I'm trying to convert the data into a more human readable text format and then generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.memory.chat_message_histories import StreamlitChatMessageHistory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor, Tool\n",
    "from langchain import LLMChain\n",
    "from langchain.callbacks.streaming_stdout_final_only import (\n",
    "    FinalStreamingStdOutCallbackHandler,\n",
    ")\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent, create_retriever_tool\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to human readable text file\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert a row to a human-readable sentence format\n",
    "def row_to_sentence(row):\n",
    "    sentence_parts = []\n",
    "    for col in df.columns:\n",
    "        # Skip columns with NaN values\n",
    "        if pd.isna(row[col]):\n",
    "            continue\n",
    "        # Format each column value into a readable sentence part\n",
    "        sentence_part = f\"{col.replace('_', ' ').upper()} is {row[col]}\"\n",
    "        sentence_parts.append(sentence_part)\n",
    "    # Combine all parts into a single sentence\n",
    "    return '. '.join(sentence_parts) + '.'\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = './data/train.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "sentences = [f\"{index + 1}. {row_to_sentence(row)}\" for index, row in df.iterrows()]\n",
    "\n",
    "# Saving the sentences to a text file\n",
    "text_file_path = './data/train.txt'\n",
    "with open(text_file_path, 'w') as file:\n",
    "    for sentence in sentences:\n",
    "        file.write(sentence + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./data/train.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "vectordb.save_local(\"<path to folder>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPT4ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = (\n",
    "    \"./models/mistral-7b-openorca.Q4_0.gguf\"  # replace with your desired local file path\n",
    ")\n",
    "llm = GPT4All(model=local_path, callbacks=[StreamingStdOutCallbackHandler()], verbose=True)\n",
    " \n",
    "chain =ConversationalRetrievalChain.from_llm(llm=llm,retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: The prompt size exceeds the context window size and cannot be processed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLaMA ERROR: The prompt is 209401 tokens and the context window is 2048!\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "res = chain({\"question\":\"some trials for the nose\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool\n",
    "tool = create_retriever_tool(\n",
    "    vectordb.as_retriever(),\n",
    "    \"search_clinical_trials_database\",\n",
    "    \"Searches and returns documents regarding clinical trials\")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "# Define llm\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "# Create agent\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more..\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrials for the nose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chains/base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    313\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    314\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    316\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chains/base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    299\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    300\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    301\u001b[0m     inputs,\n\u001b[1;32m    302\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 306\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/agents/agent.py:1127\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1127\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1136\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1137\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/agents/agent.py:924\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    921\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/agents/openai_functions_agent/base.py:104\u001b[0m, in \u001b[0;36mOpenAIFunctionsAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, with_functions, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_functions:\n\u001b[0;32m--> 104\u001b[0m     predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mpredict_messages(\n\u001b[1;32m    111\u001b[0m         messages,\n\u001b[1;32m    112\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/base.py:662\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[0;32m--> 662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/base.py:612\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    607\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    611\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 612\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/base.py:365\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    364\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    366\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    367\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    369\u001b[0m ]\n\u001b[1;32m    370\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 355\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m         )\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/base.py:507\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/openai.py:342\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_stream:\n\u001b[1;32m    339\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    340\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    341\u001b[0m     )\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_from_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    344\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/base.py:60\u001b[0m, in \u001b[0;36m_generate_from_stream\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_from_stream\u001b[39m(stream: Iterator[ChatGenerationChunk]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m     59\u001b[0m     generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m             generation \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/openai.py:311\u001b[0m, in \u001b[0;36mChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    310\u001b[0m default_chunk_class \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/openai.py:284\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain/chat_models/openai.py:282\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Request too large for gpt-3.5-turbo in organization org-E6HBJxFs9ulEaKRWe6XnwCJS on tokens per min (TPM): Limit 160000, Requested 179788. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "agent_executor ({\"input\": \"trials for the nose\"})['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
